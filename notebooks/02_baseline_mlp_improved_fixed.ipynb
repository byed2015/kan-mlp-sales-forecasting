{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec2de9c5",
   "metadata": {},
   "source": [
    "# 02_baseline_mlp_improved â€” Robust, log1p target, LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a6996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PROCESSED: c:\\Users\\byed2\\Documents\\miacd\\Aprendizaje Profundo\\Proyecto Final\\kan_mlp_sales\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports & paths\n",
    "import os, sys, json, random\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "PROJECT_DIR = Path.cwd().parent if Path.cwd().name=='notebooks' else Path.cwd()\n",
    "DATA_PROCESSED = PROJECT_DIR / 'data' / 'processed'\n",
    "MODELS = PROJECT_DIR / 'models'\n",
    "REPORTS = PROJECT_DIR / 'reports'\n",
    "for p in [DATA_PROCESSED, MODELS, REPORTS]: p.mkdir(parents=True, exist_ok=True)\n",
    "print('DATA_PROCESSED:', DATA_PROCESSED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c084a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (338738, 36) (41369, 36) (41463, 36)\n",
      "Target stats - train: min=0.001, max=13.449, mean=8.512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load processed v2 if available\n",
    "train_p = DATA_PROCESSED / 'train_processed_v2.csv'\n",
    "valid_p = DATA_PROCESSED / 'valid_processed_v2.csv'\n",
    "test_p  = DATA_PROCESSED / 'test_processed_v2.csv'\n",
    "if not train_p.exists():\n",
    "    train_p = DATA_PROCESSED / 'train_processed.csv'\n",
    "    valid_p = DATA_PROCESSED / 'valid_processed.csv'\n",
    "    test_p  = DATA_PROCESSED / 'test_processed.csv'\n",
    "assert train_p.exists(), 'No processed train file found.'\n",
    "train_df = pd.read_csv(train_p); valid_df = pd.read_csv(valid_p); test_df = pd.read_csv(test_p)\n",
    "target_col = 'Weekly_Sales'\n",
    "feature_cols = [c for c in train_df.columns if c != target_col]\n",
    "X_train = train_df[feature_cols].values.astype('float32'); y_train_raw = train_df[target_col].values.astype('float32')\n",
    "X_valid = valid_df[feature_cols].values.astype('float32'); y_valid_raw = valid_df[target_col].values.astype('float32')\n",
    "X_test  = test_df[feature_cols].values.astype('float32');  y_test_raw  = test_df[target_col].values.astype('float32')\n",
    "print('Shapes:', X_train.shape, X_valid.shape, X_test.shape)\n",
    "# Handle negative sales by clipping to positive before log1p\n",
    "y_train_raw = np.maximum(y_train_raw, 0.001); y_valid_raw = np.maximum(y_valid_raw, 0.001); y_test_raw = np.maximum(y_test_raw, 0.001)\n",
    "y_train = np.log1p(y_train_raw); y_valid = np.log1p(y_valid_raw); y_test = np.log1p(y_test_raw)\n",
    "print(f\"Target stats - train: min={y_train.min():.3f}, max={y_train.max():.3f}, mean={y_train.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e711529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset & DataLoader\n",
    "class TabularDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y): self.X = torch.from_numpy(X); self.y = torch.from_numpy(y).view(-1,1)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabularDataset(X_train, y_train); valid_ds = TabularDataset(X_valid, y_valid); test_ds = TabularDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=1024, shuffle=True); valid_loader = DataLoader(valid_ds, batch_size=2048, shuffle=False); test_loader = DataLoader(test_ds, batch_size=2048, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e00f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model: LayerNorm MLP\n",
    "in_features = X_train.shape[1]\n",
    "class MLP_LN(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256), nn.GELU(), nn.LayerNorm(256), nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128), nn.GELU(), nn.LayerNorm(128), nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64), nn.GELU(), nn.LayerNorm(64),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "model = MLP_LN(in_features)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462bd847",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Unified evaluate utility (robust to shapes/NaN/inf) =====\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def _to_1d(a):\n",
    "    arr = np.asarray(a)\n",
    "    return arr.ravel()\n",
    "\n",
    "def filter_invalid(preds, targets):\n",
    "    preds = _to_1d(preds)\n",
    "    targets = _to_1d(targets)\n",
    "    mask = ~(np.isnan(preds) | np.isnan(targets) | np.isinf(preds) | np.isinf(targets))\n",
    "    return preds[mask], targets[mask]\n",
    "\n",
    "def evaluate_model(model, loader, device='cpu', inv_transform=lambda x: x):\n",
    "    model.eval()\n",
    "    preds_all = []\n",
    "    targets_all = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            out = model(xb)\n",
    "            # Ensure 1D arrays\n",
    "            out_np = out.detach().cpu().numpy().ravel()\n",
    "            y_np = yb.detach().cpu().numpy().ravel()\n",
    "            preds_all.append(out_np)\n",
    "            targets_all.append(y_np)\n",
    "    if len(preds_all) == 0:\n",
    "        return {'mae': float('nan'), 'rmse': float('nan'), 'r2': float('nan')}, np.array([]), np.array([])\n",
    "    preds_log = np.concatenate(preds_all)\n",
    "    targets_log = np.concatenate(targets_all)\n",
    "    preds = inv_transform(preds_log)\n",
    "    targets = inv_transform(targets_log)\n",
    "    preds, targets = filter_invalid(preds, targets)\n",
    "    if preds.size == 0:\n",
    "        return {'mae': float('nan'), 'rmse': float('nan'), 'r2': float('nan')}, preds, targets\n",
    "    mae = float(mean_absolute_error(targets, preds))\n",
    "    rmse = float(np.sqrt(mean_squared_error(targets, preds)))\n",
    "    r2 = float(r2_score(targets, preds))\n",
    "    return {'mae': mae, 'rmse': rmse, 'r2': r2}, preds, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9572777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=0.784165 | valid_RMSE=6395.79 | MAE=3117.76 | R2=0.9161\n",
      "Epoch 002 | train_loss=0.175461 | valid_RMSE=5360.79 | MAE=2547.34 | R2=0.9410\n",
      "Epoch 002 | train_loss=0.175461 | valid_RMSE=5360.79 | MAE=2547.34 | R2=0.9410\n",
      "Epoch 003 | train_loss=0.154901 | valid_RMSE=5314.12 | MAE=2593.02 | R2=0.9421\n",
      "Epoch 003 | train_loss=0.154901 | valid_RMSE=5314.12 | MAE=2593.02 | R2=0.9421\n",
      "Epoch 004 | train_loss=0.143442 | valid_RMSE=5796.14 | MAE=2804.46 | R2=0.9311\n",
      "Epoch 004 | train_loss=0.143442 | valid_RMSE=5796.14 | MAE=2804.46 | R2=0.9311\n",
      "Epoch 005 | train_loss=0.133161 | valid_RMSE=6338.02 | MAE=3155.57 | R2=0.9176\n",
      "Epoch 005 | train_loss=0.133161 | valid_RMSE=6338.02 | MAE=3155.57 | R2=0.9176\n",
      "Epoch 006 | train_loss=0.127340 | valid_RMSE=4848.93 | MAE=2335.17 | R2=0.9518\n",
      "Epoch 006 | train_loss=0.127340 | valid_RMSE=4848.93 | MAE=2335.17 | R2=0.9518\n",
      "Epoch 007 | train_loss=0.121523 | valid_RMSE=4403.77 | MAE=2019.68 | R2=0.9602\n",
      "Epoch 007 | train_loss=0.121523 | valid_RMSE=4403.77 | MAE=2019.68 | R2=0.9602\n",
      "Epoch 008 | train_loss=0.118674 | valid_RMSE=4582.73 | MAE=2156.33 | R2=0.9569\n",
      "Epoch 008 | train_loss=0.118674 | valid_RMSE=4582.73 | MAE=2156.33 | R2=0.9569\n",
      "Epoch 009 | train_loss=0.114751 | valid_RMSE=6611.98 | MAE=3367.98 | R2=0.9103\n",
      "Epoch 009 | train_loss=0.114751 | valid_RMSE=6611.98 | MAE=3367.98 | R2=0.9103\n",
      "Epoch 010 | train_loss=0.112322 | valid_RMSE=5515.36 | MAE=2778.41 | R2=0.9376\n",
      "Epoch 010 | train_loss=0.112322 | valid_RMSE=5515.36 | MAE=2778.41 | R2=0.9376\n",
      "Epoch 011 | train_loss=0.108721 | valid_RMSE=5981.49 | MAE=2913.98 | R2=0.9266\n",
      "Epoch 011 | train_loss=0.108721 | valid_RMSE=5981.49 | MAE=2913.98 | R2=0.9266\n",
      "Epoch 012 | train_loss=0.100104 | valid_RMSE=4266.58 | MAE=2113.70 | R2=0.9626\n",
      "Epoch 012 | train_loss=0.100104 | valid_RMSE=4266.58 | MAE=2113.70 | R2=0.9626\n",
      "Epoch 013 | train_loss=0.098545 | valid_RMSE=4884.41 | MAE=2427.14 | R2=0.9510\n",
      "Epoch 013 | train_loss=0.098545 | valid_RMSE=4884.41 | MAE=2427.14 | R2=0.9510\n",
      "Epoch 014 | train_loss=0.097652 | valid_RMSE=4420.77 | MAE=2157.56 | R2=0.9599\n",
      "Epoch 014 | train_loss=0.097652 | valid_RMSE=4420.77 | MAE=2157.56 | R2=0.9599\n",
      "Epoch 015 | train_loss=0.096828 | valid_RMSE=6078.17 | MAE=2964.43 | R2=0.9242\n",
      "Epoch 015 | train_loss=0.096828 | valid_RMSE=6078.17 | MAE=2964.43 | R2=0.9242\n",
      "Epoch 016 | train_loss=0.095266 | valid_RMSE=4240.22 | MAE=2117.55 | R2=0.9631\n",
      "Epoch 016 | train_loss=0.095266 | valid_RMSE=4240.22 | MAE=2117.55 | R2=0.9631\n",
      "Epoch 017 | train_loss=0.094283 | valid_RMSE=4669.21 | MAE=2331.98 | R2=0.9553\n",
      "Epoch 017 | train_loss=0.094283 | valid_RMSE=4669.21 | MAE=2331.98 | R2=0.9553\n",
      "Epoch 018 | train_loss=0.093279 | valid_RMSE=5274.99 | MAE=2632.85 | R2=0.9429\n",
      "Epoch 018 | train_loss=0.093279 | valid_RMSE=5274.99 | MAE=2632.85 | R2=0.9429\n",
      "Epoch 019 | train_loss=0.092804 | valid_RMSE=5206.58 | MAE=2682.27 | R2=0.9444\n",
      "Epoch 019 | train_loss=0.092804 | valid_RMSE=5206.58 | MAE=2682.27 | R2=0.9444\n",
      "Epoch 020 | train_loss=0.093011 | valid_RMSE=3925.18 | MAE=1844.69 | R2=0.9684\n",
      "Epoch 020 | train_loss=0.093011 | valid_RMSE=3925.18 | MAE=1844.69 | R2=0.9684\n",
      "Epoch 021 | train_loss=0.091791 | valid_RMSE=4882.17 | MAE=2496.27 | R2=0.9511\n",
      "Epoch 021 | train_loss=0.091791 | valid_RMSE=4882.17 | MAE=2496.27 | R2=0.9511\n",
      "Epoch 022 | train_loss=0.091022 | valid_RMSE=5640.57 | MAE=2793.65 | R2=0.9347\n",
      "Epoch 022 | train_loss=0.091022 | valid_RMSE=5640.57 | MAE=2793.65 | R2=0.9347\n",
      "Epoch 023 | train_loss=0.090625 | valid_RMSE=5258.34 | MAE=2512.36 | R2=0.9433\n",
      "Epoch 023 | train_loss=0.090625 | valid_RMSE=5258.34 | MAE=2512.36 | R2=0.9433\n",
      "Epoch 024 | train_loss=0.089724 | valid_RMSE=4725.11 | MAE=2508.90 | R2=0.9542\n",
      "Epoch 024 | train_loss=0.089724 | valid_RMSE=4725.11 | MAE=2508.90 | R2=0.9542\n",
      "Epoch 025 | train_loss=0.086315 | valid_RMSE=4530.46 | MAE=2252.31 | R2=0.9579\n",
      "Epoch 025 | train_loss=0.086315 | valid_RMSE=4530.46 | MAE=2252.31 | R2=0.9579\n",
      "Epoch 026 | train_loss=0.085729 | valid_RMSE=4619.37 | MAE=2342.71 | R2=0.9562\n",
      "Epoch 026 | train_loss=0.085729 | valid_RMSE=4619.37 | MAE=2342.71 | R2=0.9562\n",
      "Epoch 027 | train_loss=0.085006 | valid_RMSE=5330.55 | MAE=2533.73 | R2=0.9417\n",
      "Epoch 027 | train_loss=0.085006 | valid_RMSE=5330.55 | MAE=2533.73 | R2=0.9417\n",
      "Epoch 028 | train_loss=0.084906 | valid_RMSE=4363.88 | MAE=2186.46 | R2=0.9609\n",
      "Early stopping\n",
      "Epoch 028 | train_loss=0.084906 | valid_RMSE=4363.88 | MAE=2186.46 | R2=0.9609\n",
      "Early stopping\n",
      "Best valid metrics: {'mae': 2186.461669921875, 'rmse': 4363.877175173472, 'r2': 0.9609250426292419}\n",
      "Test metrics: {'mae': 2333.67822265625, 'rmse': 4641.077461107496, 'r2': 0.9549079537391663}\n",
      "Best valid metrics: {'mae': 2186.461669921875, 'rmse': 4363.877175173472, 'r2': 0.9609250426292419}\n",
      "Test metrics: {'mae': 2333.67822265625, 'rmse': 4641.077461107496, 'r2': 0.9549079537391663}\n",
      "Saved model, metrics and predictions.\n",
      "Saved model, metrics and predictions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop with early stopping and robust evaluation\n",
    "best_rmse = float('inf'); patience = 8; wait = 0; best_state = None\n",
    "train_losses = []; valid_rmses = []\n",
    "EPOCHS = 50; max_grad_norm = 1.0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train(); total = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device); yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        total += float(loss.detach().cpu().numpy()) * xb.size(0)\n",
    "    train_loss = total / len(train_loader.dataset); train_losses.append(train_loss)\n",
    "    metrics_v, preds_v, y_v = evaluate_model(model, valid_loader, device=device, inv_transform=lambda x: np.expm1(x))\n",
    "    valid_rmses.append(metrics_v['rmse'])\n",
    "    scheduler.step(metrics_v['rmse'])\n",
    "    print(f\"Epoch {epoch:03d} | train_loss={train_loss:.6f} | valid_RMSE={metrics_v['rmse']:.2f} | MAE={metrics_v['mae']:.2f} | R2={metrics_v['r2']:.4f}\")\n",
    "    if metrics_v['rmse'] < best_rmse - 1e-4:\n",
    "        best_rmse = metrics_v['rmse']; wait = 0\n",
    "        best_state = {k:v.cpu() for k,v in model.state_dict().items()}\n",
    "        best_preds_v = preds_v.copy(); best_y_v = y_v.copy()\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print('Early stopping'); break\n",
    "\n",
    "# restore best and evaluate on test\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "val_metrics, preds_v, y_v = evaluate_model(model, valid_loader, device=device, inv_transform=lambda x: np.expm1(x))\n",
    "test_metrics, preds_t, y_t = evaluate_model(model, test_loader, device=device, inv_transform=lambda x: np.expm1(x))\n",
    "print('Best valid metrics:', val_metrics); print('Test metrics:', test_metrics)\n",
    "\n",
    "# Save artifacts\n",
    "import json, pandas as pd, torch as _torch\n",
    "_models = MODELS / 'baseline_mlp_improved.pt'\n",
    "_reports = REPORTS / 'baseline_mlp_improved_metrics.json'\n",
    "_preds_val = REPORTS / 'baseline_mlp_valid_predictions.csv'\n",
    "_preds_test = REPORTS / 'baseline_mlp_test_predictions.csv'\n",
    "_tdf = pd.DataFrame({'y_true': y_v, 'y_pred': preds_v})\n",
    "_tdf.to_csv(_preds_val, index=False)\n",
    "_tdf2 = pd.DataFrame({'y_true': y_t, 'y_pred': preds_t}); _tdf2.to_csv(_preds_test, index=False)\n",
    "_torch.save(model.state_dict(), _models)\n",
    "json.dump({'valid': val_metrics, 'test': test_metrics}, open(_reports,'w'), indent=2)\n",
    "print('Saved model, metrics and predictions.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
